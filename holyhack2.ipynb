{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'hs', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht', 'ht']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import json\n",
    "from time import sleep\n",
    "from random import randrange\n",
    "import pandas as pd\n",
    "\n",
    "url=\"https://www.google.com/search?q=halff%20indeed\"\n",
    "driver = webdriver.Safari()\n",
    "driver.get(url)\n",
    "    #rnd=randrange(1,2)\n",
    "    #sleep(rnd)\n",
    "page=driver.page_source\n",
    "driver.close()\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "soup.prettify()\n",
    "\n",
    "\n",
    "links = []\n",
    "for elem in soup.find_all(\"a\"):\n",
    "    links.append(elem.get(\"href\"))\n",
    "list_of_links=[]\n",
    "\n",
    "for elem in links:\n",
    "    if \"https\" in str(elem):\n",
    "        elem.split(':h')\n",
    "        list_of_links.append('h'+elem[1])\n",
    "print(list_of_links)\n",
    "#for elem in list_of_links:\n",
    " #   if './reviews' in elem:\n",
    "  #      print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "url=\"https://www.indeed.com/cmp/Halff-Associates,-Inc./reviews\"\n",
    "driver = webdriver.Safari()\n",
    "driver.get(url)\n",
    "    #rnd=randrange(1,2)\n",
    "    #sleep(rnd)\n",
    "page=driver.page_source\n",
    "driver.close()\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "soup.prettify()\n",
    "\n",
    "import re\n",
    "for elem in soup.find_all(\"span\", attrs={'class': 'css-82l4gy eu4oa1w0'}):\n",
    "        with open('review.txt', 'a+') as fp:\n",
    "            fp.write(str(elem))\n",
    "\n",
    "with open('review.txt', 'a+') as fp:\n",
    "    line=fp.read()\n",
    "    res = re.findall('<.*/>(.*?)</.*?>', line)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good place to start a career', 'As mentioned above, good atmosphere, pay seems to wane from expectations. I wish I had the ability to stay here longer, yet, I need to be paid for what I deserve.', 'Very friendly environment and overall great experience ', 'Yes I recommend working for the company, they have helped me start my career and they have answered any questions I have had and have been such a good company to have worked for. It is not for the lazy though, but I found the job made me learn a lot and I pushed myself to be a better person', 'Productive and fun place', 'I have been there for more than 5 years now and it has a great culture. Managers really care about your career growth and there is alot of room to grow. Overall great place to work.', 'Productive, enjoyable, and family-oriented', 'They provide training and are more than willing to help. The management will have an individual helping to mentor while working.  If you want to explore a different type of project they share work. Encourage you to finish your work and leave at 5 pm to spend time with your family, which provides a good work-life balance.', 'Lunch and Learns Fair pay Great benefits', 'Good work culture. ', 'The company seems to genuinely care about employees. 40 hour weeks were the norm, with some extra work around deadlines. I saw a lot of people get opportunities for advancement. ', 'Family orientated', 'I love everything about this company. Only leaving because Florida is too hot. Pto, insurance, 401k, holiday, overtime is all provided at this company.', 'No communication', 'No communication, no training, no respect, and no leadership. Leadership is one sided only. They are perfect and they look at you like scum everyday. Human resources is not what you think. People here just want their check and leave. There is no team family environment like they say. Management talk badly about other team leaders. Team leaders talk bad about other team leaders. This is a gossip swamp. There is no growth or career development moving forward. If you work here just do not even waste your time with these unprofessional people thinking their do not stink and trust me it does from a mile a way with that attitude and horrible leadership skills. Not even their benefits are good you have to pay high deductibles and it made just it horrible with the pandemic. ', 'None', 'Lack of leadership, communication and poor attitudes', 'Undervalue support staff', 'They do not value their support staff. Bonuses and raises are not the same as their engineers. Engineers here seem to be ok. Have seen more long time employees leave because they did not feel they were respected.', 'Great if your a workaholic', \"I worked here for 8 months and had to leave due to a personal family decision. During my time here I was often given no direction as far as what needed to be done when. Different styles for different managers which made it difficult to adhere to one company wide format. There were multiple instances where I had to stay late until sunrise due to poor coordination on projects. Had to stay up 4 nights in a row to complete a small project on time due to engineers submitting their revised work just shy of the project deadline. Was never informed ahead of time. Work always had to be done with little or no lead time. Made family life impossible to plan for. Good benefits though, and you will need them because you'll most likely have to buy pharmaceuticals to deal with the stress and weight you will gain from not being able to exercise.\", 'My experience', 'I have no experience with as a whole, but as far as my experience with San Antonio office is experience is concern, I have a bitter experience. The manager in San Antonio office is the worst person ever I have experienced in my whole professional career, he is the worst.', 'Steady, nothing more, nothing less', ' ', ' ', 'Management is delusional. They chase projects that no one else wants and consistently lose money on them. Maybe theres a reason no one else wants them...', \"Overall company culture is great, but some teams don't follow it\", \"As an EIT, most days are spent working with PM's on various projects within different CAD programs. I improved writing skills and skills with various programs but days get monotonous and some PM's are difficult to work with. The workplace culture is good for the most part, and overall the company really cares about its employees. Sometimes that doesn't apply to individual teams though.\", 'worked there for 13 years and position eleminated', 'it seemed like a good place and fast moving, then one day after 13 years my position was eliminated and with no opportunity to relocate as others were given. they were done with me after  13 years and no explanation other than automation and moving work to headquarters. I had just been part of the transition team for the new system from January to May 2017 for a new system and worked many long hours and weekend in corporate office to be laid off due to elimination of position.', 'seemed like i was useful to company for 13 years', 'job was eleimnated and no notice was given after 13 years', 'Halff is a whole company.', 'Great company loved the culture. Busy but fun! Very professional competent smart employees. Career advancement opportunities are based on your level of commitment.', 'The Google of safety consulting!!', 'Had to move out state.', 'Great place for young engineers to learn', 'As an intern, was exposed to production team meetings and functions. From this I was able to see what kinds of projects were happening around me. The internship experience was positive enough for me to seek a full-time position at the company.', 'Great place to work', 'Advancement Opportunities', 'Friends make it further than hard workers', 'Summary sums it. Accused of things that cannot be rebuted. Part of a group that was \"invisible\" to the major company. Never socialized, always worked, but yet the office pariah even though I helped profit.', 'Halff Associates', 'Overall a very enjoyable place to work.  Everyone was friendly and patient with me as an intern and I returned their kindness with hard work and quality work.', 'Great place for engineering degree', 'This is a great place to work if you have an engineering degree.  The managers were really nice, easy to get a long with.  They always had fun events, holiday activities, company outings, etc.', 'They did not value Admin. Assistants', 'Most the time I thought management were not being honest with their employees.  Not much room for advancement for Admins.  No one trusted the HR Department staff who would tell you not to do certain things then turn around and do the very things we were told not to do.  Sometimes business became slow.  Management let the Engineers get away with anything they wanted to.', 'Most the time environment was upbeat', 'Did not value Admins.', 'Somewhat relaxed work environment.', 'Large Engineering firm with a Landscape Architecture department. Fun people to work with. Good benefits and team building outside of the office.  Hard to advance once you get to a certain level.']\n"
     ]
    }
   ],
   "source": [
    "with open('review.txt', 'r') as fp:\n",
    "    line=fp.read()\n",
    "    res = re.findall('<.*?>([^(?!<br.*?/>)].*?)</.*?>', line)\n",
    "    print(res)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in res:\n",
    "    if i==\"\":\n",
    "        res.remove(i)\n",
    "    if i==\":\n",
    "\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "unsuccessful_links = []\n",
    "companies = []\n",
    "\n",
    "def scraping_pages(num_pages):\n",
    "    #Creating 'n' urls with url_roots to scrape\n",
    "    url_root = 'https://www.glassdoor.com/Explore/browse-companies.htm?overall_rating_low=0&page=' #root url\n",
    "    nums = [x+1 for x in range(num_pages)]\n",
    "    url_mains = list(map(lambda n: url_root + str(n), nums)) #adding 'n' number to call url_root\n",
    "    time.sleep(10) #give page plenty of time to load (page 1 loads first, then specified 'n' page)\n",
    "\n",
    "    for u in url_mains:\n",
    "        driver.get(u)\n",
    "        time.sleep(10)\n",
    "\n",
    "    #looking for 'Overview' links from each main search page\n",
    "        elems = driver.find_elements_by_tag_name('a') #find links on an individual search page tagged with the 'a' tag\n",
    "        company_links = []\n",
    "        for elem in elems:\n",
    "            company_link = elem.get_attribute('href') #returns every item with 'href' attribute (these are the links for each company)\n",
    "            if 'Overview' in company_link:\n",
    "                company_links.append(company_link) #each company's 'Overview' link added to company_link list\n",
    "\n",
    "    #iterating through each company's \"Overview\" url\n",
    "        for url in company_links:\n",
    "            try: #fail safe for inevitable errors\n",
    "                driver.get(url)\n",
    "                time.sleep(5)\n",
    "\n",
    "##---------------------------------- Gathering Variables - Main Page ---------------------------------##\n",
    "                name = driver.find_elements_by_xpath('//*[@id=\"EmpHeroAndEmpInfo\"]/div[3]/div[2]').text\n",
    "                size = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/ul/li[3]/div').text\n",
    "                headquarters = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/ul/li[2]/div').text\n",
    "                industry = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/ul/li[6]/div').text\n",
    "                try:\n",
    "                    num_reviews = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[3]/div[3]/a').text\n",
    "                except:\n",
    "                    num_reviews = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[4]/div[3]/a').text\n",
    "\n",
    "            #Gather Description - handling \"Read More\" button\n",
    "                try:\n",
    "                    read_more = driver.find_elements_by_class_name('css-1tgo67c.e16x8fv00') #button class\n",
    "                    read_more.click()\n",
    "                    time.sleep(2)\n",
    "                    description = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/div[1]/span').text\n",
    "                except:\n",
    "                    description = \"N/A\"\n",
    "\n",
    "            #Gather Mission - handling \"Read More\" button\n",
    "                try:\n",
    "                    read_more = driver.find_elements_by_class_name('css-1tgo67c.e16x8fv00') #button class\n",
    "                    read_more.click()\n",
    "                    time.sleep(2)\n",
    "                    mission = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/div[2]').text\n",
    "                except:\n",
    "                    mission = \"N/A\"\n",
    "\n",
    "##-------------------------------- Gathering Variables - Ratings Pop-up --------------------------------##\n",
    "            #Webpage layout 1\n",
    "                try:\n",
    "                    driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[3]/div[1]/div[2]').click()\n",
    "                    time.sleep(5) #let page load\n",
    "\n",
    "                    rating_overall = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[1]/div/div[3]').text\n",
    "                    rating_DI = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[3]/div/div[3]').text\n",
    "                    rating_CV = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[2]/div/div[3]').text\n",
    "                    rating_WL = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[4]/div/div[3]').text\n",
    "                    rating_SM = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[5]/div/div[3]').text\n",
    "                    rating_CB = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[6]/div/div[3]').text\n",
    "                    rating_CO = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[7]/div/div[3]').text\n",
    "\n",
    "                    time.sleep(np.random.choice([x/10 for x in range(7,22)])) #some time to rest\n",
    "            #Webpage layout 2\n",
    "                except:\n",
    "                    driver.get(url) #recalling url\n",
    "                    driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[4]/div[1]/div[2]').click()\n",
    "                    time.sleep(5) #let page load\n",
    "\n",
    "                    rating_overall = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[1]/div/div[3]').text\n",
    "                    rating_DI = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[3]/div/div[3]').text\n",
    "                    rating_CV = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[2]/div/div[3]').text\n",
    "                    rating_WL = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[4]/div/div[3]').text\n",
    "                    rating_SM = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[5]/div/div[3]').text\n",
    "                    rating_CB = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[6]/div/div[3]').text\n",
    "                    rating_CO = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[7]/div/div[3]').text\n",
    "\n",
    "                    time.sleep(np.random.choice([x/10 for x in range(7,22)])) #some time to rest\n",
    "\n",
    "##---------------------------------------- Creating a Dictionary ----------------------------------------##\n",
    "                companies.append({\n",
    "                    \"NAME\" : name,\n",
    "                    \"SIZE\" : size,\n",
    "                    \"LOCATION_HQ\" : headquarters,\n",
    "                    \"INDUSTRY\" : industry,\n",
    "                    \"RATING_OVERALL\" : rating_overall,\n",
    "                    \"RATING_DI\" : rating_DI,\n",
    "                    \"RATING_CV\" : rating_CV,\n",
    "                    \"RATING_WL\" : rating_WL,\n",
    "                    \"RATING_SM\" : rating_SM,\n",
    "                    \"RATING_CB\" : rating_CB,\n",
    "                    \"RATING_CO\" : rating_CO,\n",
    "                    \"NUM_REVIEWS\" : num_reviews,\n",
    "                    \"DESCRIPTION\" : description,\n",
    "                    \"MISSION\" : mission\n",
    "                                 })\n",
    "\n",
    "            except: #fail safe for inevitable errors\n",
    "                unsuccessful_links.append(url) #adding unsuccessful urls to a list\n",
    "                print('ERROR: ', url) #optional code to see list of urls that don't scrape properly\n",
    "                time.sleep(10) #extra time here to let your internet catch up after an error\n",
    "\n",
    "        print(f'Finished scraping {len(companies)} companies')\n",
    "        df = pd.DataFrame(companies)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "opts = Options()\n",
    "opts.add_argument(\"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36\")\n",
    "#opts.add_argument('headless')\n",
    "\n",
    "driver = webdriver.Safari(options=opts)\n",
    "time.sleep(5)\n",
    "url_main = 'https://www.glassdoor.com/Explore/browse-companies.htm?overall_rating_low=0&page=1&isHiringSurge=0' #main url\n",
    "\n",
    "driver.get(url_main)\n",
    "\n",
    "unsuccessful_links = [] ##UPDATE## this line to create unique list for this scrape attempt\n",
    "companies = [] ##UPDATE## this line to create unique list for this scrape attempt\n",
    "\n",
    "def scraping_pages(num_pages):\n",
    "    #Creating 'n' urls with url_roots to scrape\n",
    "    url_root = 'https://www.glassdoor.com/Explore/browse-companies.htm?overall_rating_low=0&page=' #root url\n",
    "    nums = [x+1 for x in range(num_pages)] ##UPDATE## x + __ according to where last scrape attempt left off\n",
    "    url_mains = list(map(lambda n: url_root + str(n), nums)) #adding 'n' number to call url_root\n",
    "    time.sleep(10) #give page plenty of time to load (page 1 loads first, then specified 'n' page)\n",
    "\n",
    "    for u in url_mains:\n",
    "        driver.get(u)\n",
    "        time.sleep(10)\n",
    "\n",
    "    #looking for 'Overview' links from each main search page\n",
    "        elems = driver.find_elements('a') #find links on an individual search page tagged with the 'a' tag\n",
    "        company_links = []\n",
    "        for elem in elems:\n",
    "            company_link = elem.get_attribute('href') #returns every item with 'href' attribute (these are the links for each company)\n",
    "            if 'Overview' in company_link:\n",
    "                company_links.append(company_link) #each company's 'Overview' link added to company_link list\n",
    "\n",
    "    #iterating through each company's \"Overview\" url\n",
    "        for url in company_links:\n",
    "            try: #fail safe for inevitable errors\n",
    "                driver.get(url)\n",
    "                time.sleep(5)\n",
    "\n",
    "##---------------------------------------- Handling login ------------------------------------------##\n",
    "                name = 'n' # <---- ENTER GLASSDOOR CREDENTIALS HERE\n",
    "                pw = 'pw'\n",
    "\n",
    "                try: #login\n",
    "                    username = driver.find_elements_by_id()_id(\"userEmail\")\n",
    "                    password = driver.find_elements_by_id(\"userPassword\")\n",
    "                    submit = driver.find_elements_by_xpath('//*[@id=\"InlineLoginModule\"]/div/div[2]/div/div[1]/div[3]/form/div[3]/div[1]/button')\n",
    "                    username.send_keys(name)\n",
    "                    password.send_keys(pw)\n",
    "                    submit.click()\n",
    "                    time.sleep(4) #let page load\n",
    "                except: #no login required\n",
    "                    time.sleep(2)\n",
    "                    pass\n",
    "\n",
    "##---------------------------------- Gathering Variables - Main Page ---------------------------------##\n",
    "                name = driver.find_elements_by_xpath('//*[@id=\"EmpHeroAndEmpInfo\"]/div[3]/div[2]').text\n",
    "                size = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/ul/li[3]/div').text\n",
    "                headquarters = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/ul/li[2]/div').text\n",
    "                industry = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/ul/li[6]/div').text\n",
    "                try:\n",
    "                    num_reviews = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[3]/div[3]/a').text\n",
    "                except:\n",
    "                    num_reviews = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[4]/div[3]/a').text\n",
    "\n",
    "            #Gather Description - handling \"Read More\" button\n",
    "                try:\n",
    "                    read_more = driver.find_elements_by_class_name('css-1tgo67c.e16x8fv00') #button class\n",
    "                    read_more.click()\n",
    "                    time.sleep(2)\n",
    "                    description = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/div[1]/span').text\n",
    "                except:\n",
    "                    description = \"N/A\"\n",
    "\n",
    "            #Gather Mission - handling \"Read More\" button\n",
    "                try:\n",
    "                    read_more = driver.find_elements_by_class_name('css-1tgo67c.e16x8fv00') #button class\n",
    "                    read_more.click()\n",
    "                    time.sleep(2)\n",
    "                    mission = driver.find_elements_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/div[2]').text\n",
    "                except:\n",
    "                    mission = \"N/A\"\n",
    "\n",
    "##-------------------------------- Gathering Variables - Ratings Pop-up --------------------------------##\n",
    "            #Webpage layout 1\n",
    "                try:\n",
    "                    driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[3]/div[1]/div[2]').click()\n",
    "                    time.sleep(5) #let page load\n",
    "\n",
    "                    rating_overall = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[1]/div/div[3]').text\n",
    "                    rating_DI = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[3]/div/div[3]').text\n",
    "                    rating_CV = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[2]/div/div[3]').text\n",
    "                    rating_WL = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[4]/div/div[3]').text\n",
    "                    rating_SM = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[5]/div/div[3]').text\n",
    "                    rating_CB = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[6]/div/div[3]').text\n",
    "                    rating_CO = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[7]/div/div[3]').text\n",
    "\n",
    "                    time.sleep(np.random.choice([x/10 for x in range(7,22)])) #some time to rest\n",
    "            #Webpage layout 2\n",
    "                except:\n",
    "                    driver.get(url) #recalling url\n",
    "                    driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[4]/div[1]/div[2]').click()\n",
    "                    time.sleep(5) #let page load\n",
    "\n",
    "                    rating_overall = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[1]/div/div[3]').text\n",
    "                    rating_DI = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[3]/div/div[3]').text\n",
    "                    rating_CV = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[2]/div/div[3]').text\n",
    "                    rating_WL = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[4]/div/div[3]').text\n",
    "                    rating_SM = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[5]/div/div[3]').text\n",
    "                    rating_CB = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[6]/div/div[3]').text\n",
    "                    rating_CO = driver.find_elements_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[7]/div/div[3]').text\n",
    "\n",
    "                    time.sleep(np.random.choice([x/10 for x in range(7,22)])) #some time to rest\n",
    "\n",
    "##---------------------------------------- Creating a Dictionary ----------------------------------------##\n",
    "                companies.append({ ##UPDATE## this line to create unique dictionary for this scrape attempt\n",
    "                    \"NAME\" : name,\n",
    "                    \"SIZE\" : size,\n",
    "                    \"LOCATION_HQ\" : headquarters,\n",
    "                    \"INDUSTRY\" : industry,\n",
    "                    \"RATING_OVERALL\" : rating_overall,\n",
    "                    \"RATING_DI\" : rating_DI,\n",
    "                    \"RATING_CV\" : rating_CV,\n",
    "                    \"RATING_WL\" : rating_WL,\n",
    "                    \"RATING_SM\" : rating_SM,\n",
    "                    \"RATING_CB\" : rating_CB,\n",
    "                    \"RATING_CO\" : rating_CO,\n",
    "                    \"NUM_REVIEWS\" : num_reviews,\n",
    "                    \"DESCRIPTION\" : description,\n",
    "                    \"MISSION\" : mission\n",
    "                                 })\n",
    "\n",
    "            except: #fail safe for inevitable errors\n",
    "                unsuccessful_links.append(url) #adding unsuccessful urls to a list ##UPDATE## unsuccessful_links list\n",
    "                print('ERROR: ', url)\n",
    "                time.sleep(10)\n",
    "\n",
    "        print(f'Finished scraping {len(companies)} companies') ##UPDATE## companies list name\n",
    "        df = pd.DataFrame(companies)                           ##UPDATE## df number and companies list name\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/dt_fv3nj367c2t_4tx8sbjzh0000gn/T/ipykernel_92905/3709596295.py:33: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  elems = driver.find_elements_by_tag_name('a') #find links on an individual search page tagged with the 'a' tag\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [83]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mscraping_pages\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [82]\u001B[0m, in \u001B[0;36mscraping_pages\u001B[0;34m(num_pages)\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m elem \u001B[38;5;129;01min\u001B[39;00m elems:\n\u001B[1;32m     36\u001B[0m         company_link \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mget_attribute(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhref\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m#returns every item with 'href' attribute (these are the links for each company)\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mOverview\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompany_link\u001B[49m:\n\u001B[1;32m     38\u001B[0m             company_links\u001B[38;5;241m.\u001B[39mappend(company_link) \u001B[38;5;66;03m#each company's 'Overview' link added to company_link list\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m#iterating through each company's \"Overview\" url\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "scraping_pages(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "unsuccessful:  0\n"
     ]
    }
   ],
   "source": [
    "print(len(companies))\n",
    "print('unsuccessful: ', len(unsuccessful_links))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(companies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_csv = df.to_csv('file_name.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Close driver to end session\n",
    "driver.close()\n",
    "driver.quit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unsuccessful_links8 = [] ##UPDATE## this line to create unique list for this scrape attempt\n",
    "companies8 = [] ##UPDATE## this line to create unique list for this scrape attempt\n",
    "\n",
    "def scraping_pages(num_pages):\n",
    "    #Creating 'n' urls with url_roots to scrape\n",
    "    url_root = 'https://www.glassdoor.com/Explore/browse-companies.htm?overall_rating_low=0&page=' #root url\n",
    "    nums = [x+290 for x in range(num_pages)] ##UPDATE## x + __ according to where last scrape attempt left off\n",
    "    url_mains = list(map(lambda n: url_root + str(n), nums)) #adding 'n' number to call url_root\n",
    "    time.sleep(10) #give page plenty of time to load (page 1 loads first, then specified 'n' page)\n",
    "\n",
    "    for u in url_mains:\n",
    "        driver.get(u)\n",
    "        time.sleep(10)\n",
    "\n",
    "    #looking for 'Overview' links from each main search page\n",
    "        elems = driver.find_elements_by_tag_name('a') #find links on an individual search page tagged with the 'a' tag\n",
    "        company_links = []\n",
    "        for elem in elems:\n",
    "            company_link = elem.get_attribute('href') #returns every item with 'href' attribute (these are the links for each company)\n",
    "            if 'Overview' in company_link:\n",
    "                company_links.append(company_link) #each company's 'Overview' link added to company_link list\n",
    "\n",
    "    #iterating through each company's \"Overview\" url\n",
    "        for url in company_links:\n",
    "            try: #fail safe for inevitable errors\n",
    "                driver.get(url)\n",
    "                time.sleep(5)\n",
    "\n",
    "##---------------------------------------- Handling login ------------------------------------------##\n",
    "                name = 'n' # <---- ENTER GLASSDOOR CREDENTIALS HERE\n",
    "                pw = 'pw'\n",
    "\n",
    "                try: #login\n",
    "                    username = driver.find_elements_by_id(\"userEmail\")\n",
    "                    password = driver.find_elements_by_id(\"userPassword\")\n",
    "                    submit = driver.find_elements_by_xpath('//*[@id=\"InlineLoginModule\"]/div/div[2]/div/div[1]/div[3]/form/div[3]/div[1]/button')\n",
    "                    username.send_keys(name)\n",
    "                    password.send_keys(pw)\n",
    "                    submit.click()\n",
    "                    time.sleep(4) #let page load\n",
    "                except: #no login required\n",
    "                    time.sleep(2)\n",
    "                    pass\n",
    "\n",
    "##---------------------------------- Gathering Variables - Main Page ---------------------------------##\n",
    "                name = driver.find_element_by_xpath('//*[@id=\"EmpHeroAndEmpInfo\"]/div[3]/div[2]').text\n",
    "                size = driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/ul/li[3]/div').text\n",
    "                headquarters = driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/ul/li[2]/div').text\n",
    "                industry = driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/ul/li[6]/div').text\n",
    "                try:\n",
    "                    num_reviews = driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[3]/div[3]/a').text\n",
    "                except:\n",
    "                    num_reviews = driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[4]/div[3]/a').text\n",
    "\n",
    "            #Gather Description - handling \"Read More\" button\n",
    "                try:\n",
    "                    read_more = driver.find_element_by_class_name('css-1tgo67c.e16x8fv00') #button class\n",
    "                    read_more.click()\n",
    "                    time.sleep(2)\n",
    "                    description = driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/div[1]/span').text\n",
    "                except:\n",
    "                    description = \"N/A\"\n",
    "\n",
    "            #Gather Mission - handling \"Read More\" button\n",
    "                try:\n",
    "                    read_more = driver.find_element_by_class_name('css-1tgo67c.e16x8fv00') #button class\n",
    "                    read_more.click()\n",
    "                    time.sleep(2)\n",
    "                    mission = driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[1]/div[2]').text\n",
    "                except:\n",
    "                    mission = \"N/A\"\n",
    "\n",
    "##-------------------------------- Gathering Variables - Ratings Pop-up --------------------------------##\n",
    "            #Webpage layout 1\n",
    "                try:\n",
    "                    driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[3]/div[1]/div[2]').click()\n",
    "                    time.sleep(5) #let page load\n",
    "\n",
    "                    rating_overall = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[1]/div/div[3]').text\n",
    "                    rating_DI = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[3]/div/div[3]').text\n",
    "                    rating_CV = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[2]/div/div[3]').text\n",
    "                    rating_WL = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[4]/div/div[3]').text\n",
    "                    rating_SM = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[5]/div/div[3]').text\n",
    "                    rating_CB = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[6]/div/div[3]').text\n",
    "                    rating_CO = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[7]/div/div[3]').text\n",
    "\n",
    "                    time.sleep(np.random.choice([x/10 for x in range(7,22)])) #some time to rest\n",
    "            #Webpage layout 2\n",
    "                except:\n",
    "                    driver.get(url) #recalling url\n",
    "                    driver.find_element_by_xpath('//*[@id=\"EIOverviewContainer\"]/div/div[4]/div[1]/div[2]').click()\n",
    "                    time.sleep(5) #let page load\n",
    "\n",
    "                    rating_overall = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[1]/div/div[3]').text\n",
    "                    rating_DI = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[3]/div/div[3]').text\n",
    "                    rating_CV = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[2]/div/div[3]').text\n",
    "                    rating_WL = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[4]/div/div[3]').text\n",
    "                    rating_SM = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[5]/div/div[3]').text\n",
    "                    rating_CB = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[6]/div/div[3]').text\n",
    "                    rating_CO = driver.find_element_by_xpath('//*[@id=\"reviewDetailsModal\"]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[7]/div/div[3]').text\n",
    "\n",
    "                    time.sleep(np.random.choice([x/10 for x in range(7,22)])) #some time to rest\n",
    "\n",
    "##---------------------------------------- Creating a Dictionary ----------------------------------------##\n",
    "                companies8.append({ ##UPDATE## this line to create unique dictionary for this scrape attempt\n",
    "                    \"NAME\" : name,\n",
    "                    \"SIZE\" : size,\n",
    "                    \"LOCATION_HQ\" : headquarters,\n",
    "                    \"INDUSTRY\" : industry,\n",
    "                    \"RATING_OVERALL\" : rating_overall,\n",
    "                    \"RATING_DI\" : rating_DI,\n",
    "                    \"RATING_CV\" : rating_CV,\n",
    "                    \"RATING_WL\" : rating_WL,\n",
    "                    \"RATING_SM\" : rating_SM,\n",
    "                    \"RATING_CB\" : rating_CB,\n",
    "                    \"RATING_CO\" : rating_CO,\n",
    "                    \"NUM_REVIEWS\" : num_reviews,\n",
    "                    \"DESCRIPTION\" : description,\n",
    "                    \"MISSION\" : mission\n",
    "                                 })\n",
    "\n",
    "            except: #fail safe for inevitable errors\n",
    "                unsuccessful_links8.append(url) #adding unsuccessful urls to a list ##UPDATE## unsuccessful_links list\n",
    "                print('ERROR: ', url)\n",
    "                time.sleep(10)\n",
    "\n",
    "        print(f'Finished scraping {len(companies8)} companies') ##UPDATE## companies list name\n",
    "        df8 = pd.DataFrame(companies8)                          ##UPDATE## df number and companies list name\n",
    "    return df8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scraping_pages(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}